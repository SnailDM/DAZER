
## 背景

词条匹配：为了使得舆情分析及在线监测模块，可以快速的获取和用户相关的舆情数据。需要离线将每条舆情数据在入es前，根据规则对其进行打标签，以做到舆情数据的快速筛选。其中规则为关键字的与或非组合。

目前词条匹配使用的是传统检索匹配方式，但这种方式很难解决大量同义词歧义词造成的匹配混淆，所以开始探索词条标签和文章的深度语义匹配。同时由于词条标签在业务上会随时间动态增量出现，对于未来可能出现的词条标签，也无法对其进行数据标注，故重点分析迁移学习（零样本下的深度语义匹配模型）。

 恰巧看到ACL 2018年的一篇论文《A Deep Relevance Model for Zero-Shot Document Filtering》，作者将论文中的模型命名为DAZER，结合预训练的词向量，DAZER在词向量空间构建了文档和类别的交互信息，通过门卷积网络等结构来提取、综合相关性信号，并结合对抗学习技术进一步提升模型泛化能力。DAZER结构图如下：

![DAZER结构图](https://raw.githubusercontent.com/LiuNingGit/DAZER/master/imags/20180926141619.png)

对于用于训练的文本数据，DAZER要求进行类别标注，并用少部分种子词表示该类别。对于新的类别，只要给定种子词，即可使用已训练好的模型计算新类别和测试数据之间的匹配度，而无需新类别的任何标注数据。

因为词条匹配规则，天然就可以分离出词条对应的种子词集合，且新词条的动态出现，使得论文提出的DAZER模型很契合当前业务场景。所以对论文进行了探索和复现，以下为具体的结果。

## 论文结果

Movie Review数据集，下载地址http://www.cs.cornell.edu/people/pabo/movie-review-data/

情感标签分为5类，将其中一类作为未知标签，其他四类标签及其文本数据作为训练集进行模型训练。迭代每一类未知标签后，得到5个模型，论文给出的结果如下图所示：

![论文的结果描述](https://raw.githubusercontent.com/LiuNingGit/DAZER/master/imags/20180925160458.png)


针对上文结果，存在两个疑问：

- 基于very negative和 negative的模型结果为何差别这么大？

    因为数据分布不平衡，very negative 的样本量远少于negative的样本量，所以very negative的模型的训练样本量远大于negative模型的训练样本量（训练very negative模型时，用的是negaive的样本）。所以不可能是训练数据少造成的结果差。

- 具体是什么原因造成预测结果的不准确呢?

   会不会由于某些类别，在语义空间内就很接近，从距离上很难区分开来呢。

## 原因探索

基于以上两个问题，对论文进行了复现，并基于Movie Review数据集给出了评测结果。

需要注意的是，评测数据集和论文的测试集有区别，论文中的测试集数据只包含未知标签数据，而为了和现实的环境更吻合，我们的评测数据集除了未知标签的数据外，还混合了其他标签的测试数据。评测结果如下：

![report](https://raw.githubusercontent.com/LiuNingGit/DAZER/master/imags/2018-09-25-20-01-05.jpg)

从上图我们发现，不同标签的零样本模型确实和论文的表现一致，在未知标签的预测准确度上差别也很大（0.4至0.8的差别）。但是单纯的未知标签准确率和它的召回率、其他标签的的准确率均是矛盾的度量，一般来说准确率高，往往召回率低，召回率高，准确率往往偏低（周志华《机器学习》）。同理已知标签的泛化集准确度与未知标签的泛化集准确度也是矛盾的度量。

由于单个指标的片面性，所以我们考虑更全面衡量模型的指标：混合数据的f1值。从上图可以看出，不同标签的零样本模型在测试集整体上的f1值是比较稳定的，在0.4-0.5之间。

**从这里，我们得出了第一个问题的原因：论文中衡量模型结果的指标过于片面。**

我们继续分析分类错误的标签都是怎么错的，以下5张图为5个零样本模型在混合测试集上的混淆矩阵。

![](https://raw.githubusercontent.com/LiuNingGit/DAZER/master/imags/2018-09-26-14-42-02.jpg)

上图可以看出零样本标签very negative很多分错到negative类别中。

![](https://raw.githubusercontent.com/LiuNingGit/DAZER/master/imags/2018-09-26-14-42-12.jpg)

上图可以看出零样本标签negative很多分错到very negative和neutral类别中。

![](https://raw.githubusercontent.com/LiuNingGit/DAZER/master/imags/2018-09-26-14-42-42.jpg)

上图可以看出零样本标签neutral很多分错到negative和postive类别中。

![](https://raw.githubusercontent.com/LiuNingGit/DAZER/master/imags/2018-09-26-14-42-50.jpg)

上图可以看出零样本标签postive很多分错到neutral和very postive类别中。

![](https://raw.githubusercontent.com/LiuNingGit/DAZER/master/imags/2018-09-26-14-43-02.jpg)

上图可以看出零样本标签very postive很多分错到postive类别中。

综上，从某种意义上来说，标签very negative对应的数据和negati对应的数据很接近，标签negative对应的数据和very negative、neutral对应的数据很接近，标签neutral对应的数据和negative、postive对应的数据很接近，标签postive对应的数据和neutral、very postive对应的数据很接近，标签very postive对应的数据和postive对应的数据很接近。

- 在什么情况下，带标签的数据符合上述的距离分布呢？

    这时想到了原始的电影评论数据只有情感分值（0-1），在训练前人为以0.2为阈值将其划分为5类（very negative：0-0.2，negative：0.2-0.4，neutral：0.4-0.6，positive：0.6-0.8，very positive：0.8-0.9）,其中论文和复现均是此种做法，由此可以看出从情感分值的衡量上，标签数据之间的距离符合上述分布。

    ** 这里我们得出了第二个问题的原因：由于数据、模型的随机性，造成距离接近的两类数据很容易混杂起来，无法单从相似度这一个纬度上将其区分开来。 **

示意图如下：

![](https://raw.githubusercontent.com/LiuNingGit/DAZER/master/imags/20180926170414.jpg)

- 有什么启示呢？
    - 首先想到对训练数据的要求：在训练模型时，每一个训练样本需要随机采样一个负样本（对当前类别来说），以成对计算相似度损失函数。但若训练数据的不同类别之间混杂度比较高，或者极端的情况类别互相包含（如：体育标签和足球标签同时训练），那负样本的随机会造成一定的错误。【特别注明：直观感觉，没有事实依据，以后可以进一步考证】
    - 其次对预测数据的限制：直观上感觉预测数据的类别标签应该没有较大的限制，可以预测比训练数据类别更细粒度或者更粗粒度的类别标签（甚至是包含关系）。但是类别泛化的范围感觉应该有极限，如：用体育、财经类别数据训练，来预测情感类别，效果应该不好。【特别注明：直观感觉，没有事实依据，以后可以进一步考证】

## 应用结论

