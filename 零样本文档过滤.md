
## 背景

词条匹配：为了使得舆情分析及在线监测模块，可以快速的获取和用户相关的舆情数据。需要离线将每条舆情数据在入es前，根据规则对其进行打标签，以做到舆情数据的快速筛选。其中规则为关键字的与或非组合。

目前词条匹配使用的是传统检索匹配方式，但这种方式很难解决大量同义词歧义词造成的匹配混淆，所以开始探索词条标签和文章的深度语义匹配。同时由于词条标签在业务上会随时间动态增量出现，对于未来可能出现的词条标签，也无法对其进行数据标注，故重点分析迁移学习（零样本下的深度语义匹配模型）。

 恰巧看到ACL 2018年的一篇论文《A Deep Relevance Model for Zero-Shot Document Filtering》，作者将论文中的模型命名为DAZER，结合预训练的词向量，DAZER在词向量空间构建了文档和类别的交互信息，通过门卷积网络等结构来提取、综合相关性信号，并结合对抗学习技术进一步提升模型泛化能力。

对于用于训练的文本数据，DAZER要求进行类别标注，并用少部分种子词表示该类别。对于新的类别，只要给定种子词，即可使用已训练好的模型计算新类别和测试数据之间的匹配度，而无需新类别的任何标注数据。

因为词条匹配规则，天然就可以分离出词条对应的种子词集合，且新词条的动态出现，使得论文提出的DAZER模型很契合当前业务场景。所以对论文进行了探索和复现，以下为具体的结果。

## 论文结果

Movie Review数据集，下载地址http://www.cs.cornell.edu/people/pabo/movie-review-data/

情感标签分为5类，将其中一类作为未知标签，其他四类标签及其文本数据作为训练集进行模型训练。迭代每一类未知标签后，得到5个模型，论文给出的结果如下图所示：

![论文的结果描述](https://raw.githubusercontent.com/LiuNingGit/DAZER/master/imags/20180925160458.png)


针对上文结果，存在两个疑问：

- 基于very negative和 negative的模型结果为何差别这么大？

    因为数据分布不平衡，very negative 的样本量远少于negative的样本量，所以very negative的模型的训练样本量远大于negative模型的训练样本量（训练very negative模型时，用的是negaive的样本）。所以不可能是训练数据少造成的结果差。

- 具体是什么原因造成预测结果的不准确呢?

   会不会由于某些类别，在语义空间内就很接近，从距离上很难区分开来呢，

## 原因探索

基于以上两个问题，对论文进行了复现，并基于Movie Review数据集给出了评测结果。

